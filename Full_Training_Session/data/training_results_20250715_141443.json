[
  {
    "algorithm": "ppo",
    "environment": "CartPole-v1",
    "training_time": 0.008207559585571289,
    "final_evaluation": {
      "mean_score": 56.52061788160152,
      "std_score": 11.883265227417533,
      "max_score": 77.62186090269928,
      "min_score": 45.93665385781666
    },
    "metrics": {
      "final_performance": -22.450461471548618,
      "stability_score": 0.5,
      "learning_efficiency": -10.770023457851028,
      "convergence_episode": null,
      "episodes_trained": 11,
      "converged": false,
      "targets_achieved": [],
      "final_target_reached": false
    },
    "training_history": {
      "episode_rewards": [
        56.89986990541025,
        26.809228208044942,
        40.92383533168324,
        -56.45871510184795,
        -12.771330569607104,
        1.139972195013283,
        -25.923249945407097,
        -64.24972767369051,
        -3.18823483840179,
        -22.035798631724443,
        -108.75059368954878
      ],
      "episode_lengths": [
        107.0,
        114.0,
        116.0,
        97.0,
        133.0,
        169.0,
        196.0,
        117.0,
        66.0,
        110.0,
        106.0
      ],
      "training_losses": [
        0.13093025596103727,
        0.9824283515909835,
        0.15202534292928077,
        0.22490743871405194,
        0.5724859165648841,
        0.7549342014931391,
        0.5209156372647203,
        0.16379976469967228,
        0.14590396904824132,
        0.3169448616645224,
        0.738299344165315
      ]
    }
  },
  {
    "algorithm": "ppo",
    "environment": "LunarLander-v2",
    "training_time": 0.0002422332763671875,
    "final_evaluation": {
      "mean_score": 32.27953403194976,
      "std_score": 6.752592097527388,
      "max_score": 40.616475319200156,
      "min_score": 22.91695014223906
    },
    "metrics": {
      "final_performance": 2.033836825493168,
      "stability_score": 0.5,
      "learning_efficiency": 7.108150131273327,
      "convergence_episode": 12,
      "episodes_trained": 12,
      "converged": true,
      "targets_achieved": [
        {
          "target": 0,
          "episode": 12,
          "score": 2.033836825493168
        }
      ],
      "final_target_reached": true
    },
    "training_history": {
      "episode_rewards": [
        -21.012864503600955,
        -13.335176365092147,
        -22.162300175167186,
        -27.260384128212092,
        9.894596443246295,
        -50.81841205142751,
        -28.793260604407518,
        4.803282888798696,
        46.221173300651444,
        -28.359796128698772,
        -33.024079326913274,
        149.8375480370616
      ],
      "episode_lengths": [
        99.0,
        187.0,
        149.0,
        107.0,
        195.0,
        79.0,
        133.0,
        165.0,
        153.0,
        55.0,
        174.0,
        85.0
      ],
      "training_losses": [
        0.12653987439398054,
        0.25057872733407244,
        0.8656062439744401,
        0.28310033982698046,
        0.4649522470973281,
        0.5928111756755101,
        0.3250285776969409,
        0.9943023326281393,
        0.5510837270754736,
        0.32976976280625936,
        0.7564210307525063,
        0.9083279148082615
      ]
    }
  },
  {
    "algorithm": "sac",
    "environment": "Pendulum-v1",
    "training_time": 0.0001804828643798828,
    "final_evaluation": {
      "mean_score": 25.86686205329238,
      "std_score": 7.694789854986232,
      "max_score": 38.39575556638615,
      "min_score": 14.814857892473992
    },
    "metrics": {
      "final_performance": 10.966573327471693,
      "stability_score": 0.5,
      "learning_efficiency": 9.901588734683068,
      "convergence_episode": 10,
      "episodes_trained": 10,
      "converged": true,
      "targets_achieved": [
        {
          "target": -500,
          "episode": 10,
          "score": 10.966573327471693
        }
      ],
      "final_target_reached": true
    },
    "training_history": {
      "episode_rewards": [
        -99.71866503619958,
        38.6956257880615,
        16.060297669989115,
        6.612868301673296,
        12.662393904232463,
        -6.533160459249292,
        -73.3015400067033,
        133.477387762799,
        28.18893145656076,
        53.521593893552975
      ],
      "episode_lengths": [
        61.0,
        132.0,
        109.0,
        62.0,
        85.0,
        100.0,
        196.0,
        74.0,
        169.0,
        69.0
      ],
      "training_losses": [
        0.1561481215136072,
        0.6745661762151101,
        0.6790817810200083,
        0.4725514727245811,
        0.5598037641520984,
        0.7655597786360522,
        0.9353739636913423,
        0.9682823478171826,
        0.9279897125888892,
        0.22245008404710392
      ]
    }
  },
  {
    "algorithm": "sac",
    "environment": "MountainCarContinuous-v0",
    "training_time": 0.0002579689025878906,
    "final_evaluation": {
      "mean_score": 13.897172665975194,
      "std_score": 12.26418978535736,
      "max_score": 27.971495290532545,
      "min_score": -8.483293976888007
    },
    "metrics": {
      "final_performance": 3.24947617893588,
      "stability_score": 0.5,
      "learning_efficiency": 7.892374236229974,
      "convergence_episode": 15,
      "episodes_trained": 15,
      "converged": true,
      "targets_achieved": [
        {
          "target": 0,
          "episode": 15,
          "score": 3.24947617893588
        }
      ],
      "final_target_reached": true
    },
    "training_history": {
      "episode_rewards": [
        -91.45510479963822,
        -95.65328908655376,
        -58.56181343453663,
        55.22502126167241,
        -81.26484314961134,
        7.832827684973353,
        -82.06477790861707,
        -0.8487943633208574,
        1.7782252942828718,
        6.43877454765188,
        51.324127324022506,
        -7.219535621948999,
        -47.00723365425478,
        6.88520109446801,
        95.37594739210189
      ],
      "episode_lengths": [
        76.0,
        74.0,
        70.0,
        187.0,
        194.0,
        52.0,
        191.0,
        142.0,
        83.0,
        140.0,
        174.0,
        59.0,
        122.0,
        88.0,
        199.0
      ],
      "training_losses": [
        0.6003728413754656,
        0.43542324243168107,
        0.2563195196845871,
        0.6570403774110769,
        0.7524373078042426,
        0.23772047073979072,
        0.5397171582705088,
        0.5165213633911446,
        0.9591340816597891,
        0.2786524394061025,
        0.13463738498694403,
        0.34126479545718735,
        0.7280450476079313,
        0.3183061674552165,
        0.4964584504451848
      ]
    }
  },
  {
    "algorithm": "td3",
    "environment": "Pendulum-v1",
    "training_time": 0.00018739700317382812,
    "final_evaluation": {
      "mean_score": 47.713455778902265,
      "std_score": 6.207667495131572,
      "max_score": 55.70629001104624,
      "min_score": 39.11935873352247
    },
    "metrics": {
      "final_performance": -19.489497414844422,
      "stability_score": 0.5,
      "learning_efficiency": -4.114219269730816,
      "convergence_episode": 10,
      "episodes_trained": 10,
      "converged": true,
      "targets_achieved": [
        {
          "target": -500,
          "episode": 10,
          "score": -19.489497414844422
        }
      ],
      "final_target_reached": true
    },
    "training_history": {
      "episode_rewards": [
        39.03123389901828,
        -64.13947826223274,
        16.456765623554872,
        -74.45063734786505,
        37.51937309473587,
        -12.814700361293161,
        -36.014598701299796,
        6.736798298938495,
        -86.03097270868736,
        -21.1887576833136
      ],
      "episode_lengths": [
        120.0,
        177.0,
        135.0,
        50.0,
        174.0,
        70.0,
        54.0,
        100.0,
        58.0,
        52.0
      ],
      "training_losses": [
        0.7476750822352787,
        0.23033947471662178,
        0.14189591353152511,
        0.10194036671666196,
        0.3095509196491071,
        0.3394667815734987,
        0.11339131024629416,
        0.1991517429968977,
        0.5416586439818886,
        0.47363024646648855
      ]
    }
  },
  {
    "algorithm": "td3",
    "environment": "MountainCarContinuous-v0",
    "training_time": 0.0002014636993408203,
    "final_evaluation": {
      "mean_score": 33.451388643588174,
      "std_score": 6.40505029626826,
      "max_score": 44.41243920918434,
      "min_score": 26.40783078821499
    },
    "metrics": {
      "final_performance": -22.2536292242877,
      "stability_score": 0.5,
      "learning_efficiency": -0.44312921132916505,
      "convergence_episode": null,
      "episodes_trained": 12,
      "converged": false,
      "targets_achieved": [],
      "final_target_reached": false
    },
    "training_history": {
      "episode_rewards": [
        4.750601978113648,
        38.11763448220611,
        -83.1259677865944,
        -12.969773228149077,
        10.113695476889678,
        -86.26653344145363,
        -14.741897658486737,
        -18.538342457593682,
        -8.718431013153207,
        64.59620131557138,
        -14.718819419143685,
        -58.16642403076363
      ],
      "episode_lengths": [
        119.0,
        73.0,
        181.0,
        87.0,
        98.0,
        96.0,
        158.0,
        56.0,
        151.0,
        148.0,
        86.0,
        55.0
      ],
      "training_losses": [
        0.384140848691353,
        0.6432601356719668,
        0.8726441784484755,
        0.2848995774773604,
        0.5772941550476764,
        0.9856097737982707,
        0.3532408982563412,
        0.6549205483712953,
        0.9446259580545786,
        0.7381065280378621,
        0.2807165440900336,
        0.11963132550773659
      ]
    }
  },
  {
    "algorithm": "ddpg",
    "environment": "Pendulum-v1",
    "training_time": 0.00017189979553222656,
    "final_evaluation": {
      "mean_score": 4.474438009361922,
      "std_score": 9.39093544144933,
      "max_score": 14.548082757573582,
      "min_score": -9.434140752571674
    },
    "metrics": {
      "final_performance": -12.02230856136373,
      "stability_score": 0.5,
      "learning_efficiency": 6.7606591450676,
      "convergence_episode": 10,
      "episodes_trained": 10,
      "converged": true,
      "targets_achieved": [
        {
          "target": -500,
          "episode": 10,
          "score": -12.02230856136373
        }
      ],
      "final_target_reached": true
    },
    "training_history": {
      "episode_rewards": [
        -104.48268245343803,
        16.671199258691548,
        -60.356692266012246,
        15.466649936905307,
        -7.628124712612987,
        -31.48651057948542,
        38.36409388470317,
        40.43673558793187,
        6.034142573652573,
        -33.241896843973066
      ],
      "episode_lengths": [
        89.0,
        159.0,
        89.0,
        184.0,
        86.0,
        183.0,
        155.0,
        60.0,
        59.0,
        159.0
      ],
      "training_losses": [
        0.7386617207215438,
        0.3207521980850717,
        0.28945557265341376,
        0.687481005031663,
        0.8012021348848651,
        0.4159911753249199,
        0.12598647402119928,
        0.6503451468167999,
        0.900687931764473,
        0.48548493654973
      ]
    }
  },
  {
    "algorithm": "ddpg",
    "environment": "MountainCarContinuous-v0",
    "training_time": 0.00024271011352539062,
    "final_evaluation": {
      "mean_score": 16.799379876150255,
      "std_score": 5.602848603124802,
      "max_score": 22.146144460797032,
      "min_score": 6.427100741912938
    },
    "metrics": {
      "final_performance": 5.039087849487268,
      "stability_score": 0.5,
      "learning_efficiency": 4.370704895853549,
      "convergence_episode": 14,
      "episodes_trained": 14,
      "converged": true,
      "targets_achieved": [
        {
          "target": 0,
          "episode": 14,
          "score": 5.039087849487268
        }
      ],
      "final_target_reached": true
    },
    "training_history": {
      "episode_rewards": [
        14.282396960709,
        -24.184831765483466,
        -70.45973915078683,
        -69.59602044672415,
        -63.56334688875582,
        -3.4498091671183704,
        60.25741362675827,
        19.175678115729283,
        -47.05771977544721,
        28.49604127910052,
        33.47035941346104,
        -12.60689988943055,
        42.96102517099364,
        -7.291863390418126
      ],
      "episode_lengths": [
        85.0,
        192.0,
        75.0,
        181.0,
        98.0,
        110.0,
        158.0,
        102.0,
        192.0,
        166.0,
        171.0,
        179.0,
        164.0,
        193.0
      ],
      "training_losses": [
        0.29227794513701155,
        0.4950791395292867,
        0.6881591936768553,
        0.45086097850000306,
        0.11102095993567171,
        0.807869510972101,
        0.8035907687036529,
        0.8651641255753283,
        0.8960117712560992,
        0.36793932799399254,
        0.6563365432374757,
        0.7403932307652306,
        0.8440774598498793,
        0.6838733744470038
      ]
    }
  }
]